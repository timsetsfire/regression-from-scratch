{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timsetsfire/regression-from-scratch/blob/master/Exercise%20Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YuWq36boMxf"
      },
      "source": [
        "## Solution\n",
        "\n",
        "In this book we'll demonstrate a method to pick the \"best\" $\\lambda$ for $L_2$ regularization.  I say \"best\" because the choosen $\\lambda$ will be best with regard to the way we sample the data.  \n",
        "\n",
        "A general outline of the solution\n",
        "\n",
        "* Split our data up into train, validation and test datasets\n",
        "* Create a list of $\\lambda$'s to loop through\n",
        "* With each loop, we'll calc the regularized beta solution with the training data and calc the mean square error on our validation data.\n",
        "* The betas corresponding to the $\\lambda$ which gave the best sum of squared error will be tested on on the test data along side the OLS solution\n",
        "\n",
        "Recall our regularized betas can be calc'd as \n",
        "$$\\beta_\\lambda = (X^TX + \\lambda I)^{-1}X^Ty$$\n",
        "and that out OLS solution is\n",
        "$$\\beta_{OLS} = (X^TX)^{-1}X^Ty$$\n",
        "\n",
        "$I$ is an n by n identity matrix, where n is the number of features in $X$.\n",
        "\n",
        "If you don't standardize your data, you must add a bias.  Since we don't want to regularize the bias set $I_{1,1} = 0$ (this is the top left most entry - I'm not starting my indexing with 0's)\n",
        "\n",
        "The mean square error (MSE) will be our cost function\n",
        "\n",
        "$$ MSE = \\frac{1}{m}(y - X\\beta)^T(y-X\\beta)$$\n",
        "\n",
        "with $m$ equal to the number of observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "5kt8QQJVoMxh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split  # used to split up out data\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.preprocessing import StandardScaler # used to standardize data\n",
        "import numpy as np \n",
        "import seaborn as sns # my favorite plotting tool\n",
        "from pandas import DataFrame "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "AdEImPYyoMxh"
      },
      "outputs": [],
      "source": [
        "lin_reg_data = load_diabetes(return_X_y = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "_6tKuLOCoMxi"
      },
      "outputs": [],
      "source": [
        "X = lin_reg_data.data\n",
        "X = np.matrix(X)\n",
        "y = lin_reg_data.target\n",
        "y = np.matrix(y).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXakMRHhoMxi",
        "outputId": "943563ae-c14e-4c6e-d625-85d56ca5d698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best error and lambda:  0.46817964308514426 69.87575351793703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## split our data into three sets: training, validation and test\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X,y,test_size=0.1, random_state = 42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=0.3, random_state = 42)\n",
        "\n",
        "## create StandardScalers to standardize both X and y\n",
        "ss_x = StandardScaler()  \n",
        "ss_y = StandardScaler()\n",
        "\n",
        "## fit the standardizer on the training data. \n",
        "ss_x.fit(X_train)  \n",
        "ss_y.fit(y_train)\n",
        "\n",
        "## standardize all the data \n",
        "## and cast everything as a matrix \n",
        "X_train = np.matrix(ss_x.transform(X_train))\n",
        "X_val = np.matrix(ss_x.transform(X_val))\n",
        "X_test = np.matrix(ss_x.transform(X_test))\n",
        "\n",
        "y_train = np.matrix(ss_y.transform(y_train))\n",
        "y_val = np.matrix(ss_y.transform(y_val))\n",
        "y_test = np.matrix(ss_y.transform(y_test))\n",
        "\n",
        "## get the number of observations and features\n",
        "m,n = X_train.shape\n",
        "\n",
        "## create the identity matrix\n",
        "I = np.eye(n)\n",
        "\n",
        "# calc the largest lambda (just a rule of thumb calculation)\n",
        "reg = np.max( np.fabs( X_train.T*y_train)/m)/1e-3\n",
        "best_lambda = reg\n",
        "best_error = np.Infinity\n",
        "\n",
        "## create list of lambdas to loop through\n",
        "lambdas = np.exp(np.linspace(-10,np.log(reg),100))\n",
        "\n",
        "## initialize list to store the sum of squared errors for each loop\n",
        "sses = []\n",
        "for reg in lambdas:\n",
        "    b = np.linalg.inv( X_train.T*X_train + reg*I)*X_train.T*y_train\n",
        "    error = ((y_val - X_val*b).T * (y_val - X_val*b))/X_val.shape[0]\n",
        "    sses.append(error[0,0])\n",
        "    if error[0][0] < best_error:\n",
        "        best_error = error[0,0]\n",
        "        best_lambda = reg\n",
        "    #print(\"{: <8} \\t {}\".format(np.round(reg,6),error[0,0]))\n",
        "print(\"best error and lambda: \", best_error, best_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "ZNSJ0hEmoMxj",
        "outputId": "6ea93690-fc1e-4721-f9f9-6e8fa83f78c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y, data. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fc310b65750>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "cv = DataFrame([lambdas, sses]).T\n",
        "cv.columns = [\"lambda\", \"cost\"]\n",
        "sns.lmplot('lambda','cost',cv,fit_reg=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpv2-7vOoMxk"
      },
      "source": [
        "The plot above is based on the validation data.  The $x$ axis is the $lambda$, i.e., how much we penalize our cost function, and the $y$ axis is the average sum of squared errors for each corresponding $\\lambda$.  Moving from left to right, we are increasing our penality.  It's interesting - the OLS solution corresponds to $\\lambda = 0$, but our regularized solution with $lambda \\approx 36$ performs best.  \n",
        "\n",
        "Our choices to this point have been independent of the test data, so let's test how well our regularized beta measures up against the OLS beta by calc the mean square error for the test data set with each parameter set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YUXQdjaoMxk",
        "outputId": "50ec2789-0163-4ee4-d6ca-a953f4344588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results on test data\n",
            "regularized b results in cost:  0.4524548975266446\n",
            "ols b results in cost: 0.44118039340128457\n"
          ]
        }
      ],
      "source": [
        "reg = best_lambda\n",
        "# calculate the betas on the training data\n",
        "b = np.linalg.inv( X_train.T*X_train + reg*I)*X_train.T*y_train\n",
        "b_ols = np.linalg.inv(X_train.T*X_train)*X_train.T*y_train\n",
        "\n",
        "# calc errors on the test data\n",
        "error = (y_test - X_test*b).T*(y_test - X_test*b) / X_test.shape[0]\n",
        "error_ols = (y_test - X_test*b_ols).T*(y_test - X_test*b_ols) / X_test.shape[0]\n",
        "print(\"results on test data\")\n",
        "print(\"regularized b results in cost: \",error[0,0])\n",
        "print(\"ols b results in cost: {}\".format(error_ols[0,0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbUzwjyOoMxl"
      },
      "source": [
        "Our regularized solution outperforms the OLS solution.  Keep in mind that if you change the seed in the test_train_split, you will get a different story. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 \n",
        "\n",
        "Add regularization to Gradient Descent\n",
        "\n",
        "Note that when we add regularization to Gradient Descent -> the best lambda is going to be different from the one in the previous exercise.  "
      ],
      "metadata": {
        "id": "C1kTGUpHo4u6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "collapsed": true,
        "id": "bSyylPxUoMxl"
      },
      "outputs": [],
      "source": [
        "## create the objective function \n",
        "\n",
        "class MSE(object):\n",
        "    def valueAt( x, y, beta):\n",
        "        yhat = x * beta\n",
        "        e = y - yhat\n",
        "        return e.T*e / x.shape[0]\n",
        "    def gradientAt(x, y, beta):\n",
        "        yhat = x * beta\n",
        "        e = y - yhat\n",
        "        return -x.T*e / x.shape[0]\n",
        "  \n",
        "class L2(object):\n",
        "    def valueAt(b):\n",
        "        return 1/2*linalg.norm(b) \n",
        "    def gradientAt(b):\n",
        "        return b\n",
        "    \n",
        "class GradientDescent(object):\n",
        "    def __init__(self, cost_function=MSE, tolerance=1e-6, penalty_function = L2, regularization=None):\n",
        "        self.cost_function = cost_function\n",
        "        self.penalty_function = penalty_function\n",
        "        self.tol = tolerance\n",
        "        self.iter = 0\n",
        "        self.beta = None\n",
        "        self.regularization = regularization\n",
        "        \n",
        "    def optimize(self, X,y,learning_rate=0.1,init_params=None):\n",
        "        if init_params is None:\n",
        "            beta = np.matrix( np.zeros(X.shape[1])).T\n",
        "        else:\n",
        "            beta = init_params\n",
        "        grad = self.cost_function.gradientAt(X,y,beta)\n",
        "        if self.regularization is not None:\n",
        "            ## new line\n",
        "            grad += self.regularization * self.penalty_function.gradientAt(beta)\n",
        "        prev_beta = beta\n",
        "        beta = beta - learning_rate*grad\n",
        "        ## several termination criteria to use\n",
        "        ## abs change in beta is small\n",
        "        ## abs change in beta / norm of beta \n",
        "        ## abs change in object is small\n",
        "        ## here we use magitute of the gradient\n",
        "        while np.linalg.norm(prev_beta - beta)/np.linalg.norm(beta) > self.tol:\n",
        "            prev_beta = beta\n",
        "            self.iter += 1\n",
        "            grad = self.cost_function.gradientAt(X,y,beta)\n",
        "            if self.regularization is not None:\n",
        "              ## new line\n",
        "              grad += + self.regularization * self.penalty_function.gradientAt(beta)\n",
        "            beta = beta - learning_rate*grad\n",
        "        self.beta = beta\n",
        "        return beta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression = GradientDescent(regularization = 0.1)\n",
        "parameters = [\"bias\"]\n",
        "parameters.extend( [\"x{}\".format(i) for i in range(X.shape[1]-1)])\n",
        "sbeta_gd = linear_regression.optimize(X_train,y_train,learning_rate=0.1)\n",
        "DataFrame( np.concatenate( (b_ols, sbeta_gd),axis=1),\n",
        "          index = parameters,\n",
        "          columns = [\"b_ols\", \"gd beta\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "cBmd4xpKpQLj",
        "outputId": "a84c132f-4572-4328-8648-be9565314284"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         b_ols   gd beta\n",
              "bias  0.005077  0.012528\n",
              "x0   -0.155420 -0.135430\n",
              "x1    0.342506  0.321547\n",
              "x2    0.184195  0.173203\n",
              "x3   -0.614662 -0.079114\n",
              "x4    0.351174 -0.060027\n",
              "x5    0.115964 -0.114155\n",
              "x6    0.169882  0.102929\n",
              "x7    0.502954  0.269117\n",
              "x8    0.023705  0.038443"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb6d0bcb-63a3-4b92-8535-5b5fe603cd48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b_ols</th>\n",
              "      <th>gd beta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bias</th>\n",
              "      <td>0.005077</td>\n",
              "      <td>0.012528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x0</th>\n",
              "      <td>-0.155420</td>\n",
              "      <td>-0.135430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x1</th>\n",
              "      <td>0.342506</td>\n",
              "      <td>0.321547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x2</th>\n",
              "      <td>0.184195</td>\n",
              "      <td>0.173203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x3</th>\n",
              "      <td>-0.614662</td>\n",
              "      <td>-0.079114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x4</th>\n",
              "      <td>0.351174</td>\n",
              "      <td>-0.060027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x5</th>\n",
              "      <td>0.115964</td>\n",
              "      <td>-0.114155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x6</th>\n",
              "      <td>0.169882</td>\n",
              "      <td>0.102929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x7</th>\n",
              "      <td>0.502954</td>\n",
              "      <td>0.269117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x8</th>\n",
              "      <td>0.023705</td>\n",
              "      <td>0.038443</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb6d0bcb-63a3-4b92-8535-5b5fe603cd48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb6d0bcb-63a3-4b92-8535-5b5fe603cd48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb6d0bcb-63a3-4b92-8535-5b5fe603cd48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE.valueAt(X_val, y_val, sbeta_gd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hN_vRK2q_UZ",
        "outputId": "20eaf08a-9ae9-4a7f-ac1d-260353f3e029"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.47136222]])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE.valueAt(X_val, y_val, b_ols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1lg_0hcveOi",
        "outputId": "e1f2bdb8-57c5-4208-e269-0f5fe4f89e46"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.4811709]])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dt9l93FRzG0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:pgh_data_science]",
      "language": "python",
      "name": "conda-env-pgh_data_science-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Exercise 2 Solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}